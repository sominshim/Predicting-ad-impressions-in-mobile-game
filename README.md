# Predicting-ad-impressions-in-mobile-game

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2455f923-8fce-41fa-8a6a-b95584ee2f4e/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2455f923-8fce-41fa-8a6a-b95584ee2f4e/Untitled.png)

**Figure 1** Overview design of the proposed system development

# 1. Target Selection

â‡’ tutorial event ì—ì„œ selection ì§„í–‰

tutorial data ë³´ê°„

- event_params_ad_id, user_properties_ad_id í•©ì§‘í•©
â‡’ event_params_ad_id ê°€ user_properties_ad_idë¥¼ í¬í•¨í•¨. 1row ë¹¼ê³ 
- user_pseudo_id

**[target ëŒ€ìƒ]**

- tutorialì„ ëª¨ë‘ ì™„ë£Œí•œ user
: tutorial_id = 1,2,3,4 í¬í•¨ & 'event_previous_timestamp' == np.nan
- ~~(ìœ„ ë‚´ìš©ì— í¬í•¨ë¨)~~ ì‹ ~~ê·œ user 
: ìš°ë¦¬ê°€ ë°›ì€ ë°ì´í„°ê¸°ê°„ ì „ì— ì²˜ìŒ ì ‘ì†í•œ user : ad_idë¡œ groupbyí•œ í›„, tutorialì˜ ga_session_number/tutorial_idê°€ 1ì´ ì—†ëŠ” user~~
- day7 ê¹Œì§€ ë°ì´í„°ê°€ ìˆëŠ” user
: ì²« ì ‘ì†ì¼ì´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ë‚ ì˜ ì¼ì£¼ì¼ ì „ë³´ë‹¤ ë‚˜ì¤‘ì¸ user ì œê±°
ex) 0101 ~ 0130 â†’ 0101 ~ 0123 â‡’ 0124ì— ë“¤ì–´ì˜¨ userê°€ day 7 ì´ ìˆì„ ìˆ˜ê°€ ì—†ê¸° ë•Œë¬¸.

~~ad_id not null - stage ì—°ì†ì ì´ì§€ ì•ŠìŒ â†’ ad_id is null - stage ë§¤ì¹­
ad_id not null stage ë¹ ì§„ ê°œìˆ˜ = ad_id is null ê°œìˆ˜ í˜¹ì‹œ ê°™ìœ¼ë©´,,??!! ë‘ë‘¥íƒ
 â‡’ knnìœ¼ë¡œ ã…‹ã…‹ã…‹~~

ì¬ì„¤ì¹˜ì (ad_idëŠ” ê°™ì§€ë§Œ user_pseudo_idëŠ” ë‹¤ë¥¸ user) 

ì¬ì„¤ì¹˜ì‹œ ë³´í†µ user_level ì´ reset ë¨. ê·¼ë° resetë˜ì§€ ì•Šì€ user_levelì€ ~~ga_session_number ë¡œ ë³´ê°„í•  ìˆ˜ ìˆìŒ.~~

(ë°©ë²• : ga_session_numberê°€ 1ë¡œ resetë˜ëŠ” ë¶€ë¶„ë¶€í„° reset 
â‡’ ga_session_number ë„ í•­ìƒ resetë˜ëŠ” ê²ƒì€ ì•„ë‹˜..

- ì¬ì„¤ì¹˜ í›„ pseudo_idê°€ ë°”ë€Œì§€ ì•ŠëŠ” ê²½ìš° ì¡´ì¬ â‡’ ì–¼ë§ˆë‚˜ ì¡´ì¬í•˜ëŠ”ì§€ ë³´ì

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6ee52968-8e07-4d2b-aaa6-0b7f9832fb18/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6ee52968-8e07-4d2b-aaa6-0b7f9832fb18/Untitled.png)

ì¬ì„¤ì¹˜ì â†’ day ì§€ì†. ì¦‰ ê³ ë ¤í•˜ì§€ ì•ŠìŒ

# 2. Split train/test

1. tutorial ë¡œ ad_idë³„ day_0 ì¶”ì¶œ
2. ads ì˜ dateì™€ day_0ë¡œ dayê³„ì‚°
3. day 2-7 ëˆ„ì  imps ê°’ì´ 1 ì´ìƒì¸ ì‚¬ëŒ = 1 / 0ì¸ ì‚¬ëŒ = 0
â†’ ì´ ê¸°ì¤€ìœ¼ë¡œ ë¹„ìœ¨ë§ì¶° train, test split ëœ total ad_id, train(1)/test(0) dataframe ìƒì„±í•˜ê³  ê³µìœ 

# 3. Preprocessing

trainì— í¬í•¨ëœ ad_idë¥¼ ê°€ì§€ê³ 

ê° eventì—ì„œ ['device_is_limited_ad_tracking'] == 'True'ì¸ ad_id ì œê±°

## Step1) ì—‘ì…€ì‹œíŠ¸ì— ë‚˜ì™€ìˆëŠ” ì»¬ëŸ¼ ì¶”ì¶œ

[https://drive.google.com/file/d/1w0gzVq-K8vcYnn73HCQB3zS2C8Cum_-2/view](https://drive.google.com/file/d/1w0gzVq-K8vcYnn73HCQB3zS2C8Cum_-2/view)

## Step2) ì—°ì†í˜•, ì¹´í…Œê³ ë¦¬í˜• ë°ì´í„° íŒŒì•…

- ë°ì´í„° ë³€í˜•

    ex) ì‹¤ì œ ë°ì´í„°ëŠ” intí˜•ì´ì§€ë§Œ ë³¸ì§ˆì  ì˜ë¯¸ëŠ” categoryí˜• dataì¼ ê²½ìš° ë°”ê¿”ì„œ ë¶„ì„

    - code

        ë³¸ì§ˆì  ì˜ë¯¸ íŒŒì•…ì€ ê°ê° í•´ì•¼í•¨

        ```python
        #int strìœ¼ë¡œ ë³€í™˜
        event_df['column_name'] = event_df['column_name'].astype(str)
        ```

- í†µê³„ì¹˜ í™•ì¸
    - ê°œë³„ featureê°€ ì–´ë–¤ ë¶„í¬ë¥¼ ë³´ì´ëŠ”ì§€
    - numeric feature :
    - count(total, null ë“±), mean, std, min, max ë“±
    - ì •ê·œë¶„í¬ë¥¼ ë³´ì´ëŠ”ì§€ (normality), ì¹˜ìš°ì³¤ëŠ”ì§€ (skewness), íŠ¹ì • ê°’ì— ëª°ë ¤ìˆëŠ”ì§€ (low variance). 
       ë¶„í¬ ëª¨ì–‘ì— ë”°ë¼ì„œ transformationì´ í•„ìš”í•  ìˆ˜ ìˆìŒ.
    - categorical feature :
    - count(total, null ë“±), unique value count, mode, frequency table ë“±
    - í•œ ë‘ê°€ì§€ ì¹´í…Œê³ ë¦¬ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€ (Imbalanced), ê³ ë¥´ê²Œ í¼ì ¸ìˆëŠ”ì§€. 
       ê³ ë¥´ê²Œ í¼ì§„ ê²½ìš°ê°€ ë” ë§ì€ ì •ë³´ë¥¼ ì œê³µí•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ.

## Step3) **NaN ê°’ ì²˜ë¦¬**

ë°ì´í„° ì„¸íŠ¸ì˜ ê°’ ì¤‘ ëª‡ í¼ì„¼íŠ¸ê°€ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸

```python
# how many total missing values do we have?
total_cells = np.product(nfl_data.shape)
total_missing = missing_values_count.sum()

# percent of data that is missing
(total_missing/total_cells) * 100
```

1. Drop missing values
    - Nanê°’ì´ ì•„ë‹Œ Nan ì˜ë¯¸ì˜ ê°’ â†’ Nanìœ¼ë¡œ ì±„ìš°ê¸°
    ex) 999, 'x'

        ```python
        missing_values=['??','na','X','999999']
        df = df.replace(missing_values, np.NaN)
        ```

    - drop column (NaN > 50%)

        ```python
        NAN = [(c, df[c].isna().mean()*100) for c in df]
        NAN = pd.DataFrame(NAN, columns=["column_name", "percentage"])
        NAN = NAN[NAN.percentage > 50]
        NAN.sort_values("percentage", ascending=False)
        ```

    - í•œìª½ì— ì¹˜ìš°ì³ì ¸ìˆì„ ê²½ìš° featureì œê±°
    ìˆ«ìí˜• â†’ ì™œë„ standard,/ minmax / normalize/ log ë³€í™˜/... ë“± í•¨ìˆ˜ë¡œ êµ¬í˜„í•´ì„œ ì ìš©

        ì¹´í…Œê³ ë¦¬í˜• â†’ ë¶„ì‚° threshold=0.5 ? 
        [https://colab.research.google.com/drive/1TNPqL-d8a_lQx-ypSCxb3-pUXgSGdN7C?usp=sharing](https://colab.research.google.com/drive/1TNPqL-d8a_lQx-ypSCxb3-pUXgSGdN7C?usp=sharing)

    - 

2. Filling in missing values

    [ëˆ„ë½ ë°ì´í„°(Missing value)ë¥¼ ì²˜ë¦¬í•˜ëŠ” 7ê°€ì§€ ë°©ë²• / Data Imputation](https://dining-developer.tistory.com/19)

    - ad_id 
    user_pseudo_id ê°€ ê°™ì€ ad_idë¡œ ëŒ€ì²´ â†’ drop
    - numeric feature
    â†’ fill mean/median value
        - Mean - ì´ìƒì¹˜ê°€ ì—†ì„ ê²½ìš°, í‰ê· ì´ ì´ìƒì¹˜ì— ì˜í–¥ì„ ë§ì´ ë°›ê¸° ë•Œë¬¸ @
        - Median - ì´ìƒì¹˜ê°€ ë§ì„ ê²½ìš°

        ```python
        # df["Math"] = df["Math"].astype("float64")
        m = round(df["Math"].mean(), 2)
        df["Math"].fillna(m, inplace=True)

        import numpy as np
        from sklearn.impute import SimpleImputer
        imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
        imp_mean.fit(X)
        ```

        [sklearn.impute ì‚¬ìš©ë²•](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)

        ì°¸ê³ ) ë°ì´í„°ê°€ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë‚˜ëˆ„ì–´ì§„ ê²½ìš°ëŠ” ë°˜ë“œì‹œ fit() í•¨ìˆ˜ì™€ transform() í•¨ìˆ˜ë¥¼ ë”°ë¡œ ì‚¬ìš©

        - ğŸ’¡Question

            ```python
            transformer.fit(x_train) #SimpleImputer ëª¨ë¸ì— x_train ë°ì´í„° ì ìš© (í‰ê· ê°’ ê³„ì‚°)
            x_train = transformer.transform(x_train) 
            x_test = transformer.transform(x_test)
            ```

        í•œìª½ì— ì¹˜ìš°ì³ì ¸ìˆì„ ê²½ìš° featureì œê±°
        ìˆ«ìí˜• â†’ ì™œë„ standard,/ minmax / normalize/ log ë³€í™˜/... ë“± í•¨ìˆ˜ë¡œ êµ¬í˜„í•´ì„œ ì ìš©

    - categorical feature
        - ë¹ˆë„ ë†’ì€ ê°’ìœ¼ë¡œ ì±„ìš°ê¸° Mode

            ```python
            imp1 = SimpleImputer(missing_values = np.nan, strategy='most_frequent')
            ```

        - knnëª¨ë¸ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡
            - code

                ```python
                # categorical featureì˜ ê²½ìš°, mode ë˜ëŠ” classification modelì„ í™œìš© (ex. KNN)
                df['col'].fillna(df['col'].mode()[0])

                # mode ê³„ì‚° (2ê°€ì§€ ë°©ë²•ì€ ë™ì¼í•¨)
                mode = df[col].value_counts().index[0]
                mode = df[col].mode()[0]

                # KNN model í™œìš©
                # modelì— ë°ì´í„°ë¥¼ ë„£ê¸° ìœ„í•´ì„œëŠ” categorical valueë¥¼ ê°ê° ê²½ìš°ì— ë§ëŠ” numeric valueë¡œ ë³€í™˜í•´ì¤˜ì•¼í•¨ (label encoding). ìì„¸í•œ encoding ë°©ë²•ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ 2.2.8ì—ì„œ ë‹¤ë£¸.
                from sklearn.preprocessing import LabelEncoder

                encoder_X = LabelEncoder()
                encoder_y = LabelEncoder()

                # missing valueê°€ ì „í˜€ ì—†ëŠ” ê¹¨ë—í•œ ë°ì´í„°ì…‹ì„ ë°œë¼ë‚´ì„œ KNN ì•Œê³ ë¦¬ì¦˜ì„ í•™ìŠµì‹œì¼œì•¼ í•¨
                train_X = train_X.apply(encoder_X.fit_transform)
                train_y = encoder_y.fit_transform(train_y)

                from sklearn.neighbors import KNeighborsClassifier

                knn = KNeighborsClassifier(n_neighbors=5).fit(train_X, train_y)

                # KNN ì˜ˆì¸¡ê°’ìœ¼ë¡œ missing value ëŒ€ì²´í•˜ê¸°
                # colì€ missing valueê°€ ì¡´ì¬í•˜ì—¬ ëŒ€ì²´ê°€ í•„ìš”í•œ column, ind_colsëŠ” missing valueê°€ ì—†ê³  ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•œ ê¸°ì¤€ columnë“¤.
                df_null_only = df[df.isnull().any(axis=1)]
                df_null_only[col] = knn.predict(df_null_only[ind_cols].apply(lambda x: encoder.fit_transform(x)))

                # ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì°¨ê¸°
                df_final = pd.concat([train_X, df_null_only], axis=0)

                # ì‹¤ì œ categorical valueë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŒ.
                LabelEncoder.inverse_transform(df_null_only[col])
                ```

## Step4) Outlier ì²˜ë¦¬

1. outlier ì œê±°

    â†’ ad_id target_dfì— outlier columns(0/1) ë§Œë“¤ì–´ì„œ ì œê±° ëŒ€ìƒí‘œì‹œ

2. outlier ëŒ€ì²´

## Step5) feature engineering

[feature engineering](https://www.notion.so/feature-engineering-941f6f6e38d1481ebd5e5b3f0047d36b)

1. feature extraction ìƒˆë¡œìš´ feature ìƒì„±
ex) featureë“¤ì˜ ì¡°í•©ìœ¼ë¡œ, timeê´€ë ¨ ë“±,,
2. day ê³„ì‚° â†’ groupby ad_id ga_session_id ['timestamp'].min() â†’ session_start_date
session_start_date - day0 date (tutorial)
3. day0, 1 ì— í•´ë‹¹í•˜ëŠ” feature ë§Œë“¤ê¸° (ì§‘ê³„)
4. Target: ads â†’ day 2~7 ëˆ„ì í•©

---

ì¶”ê°€ feature ìƒì„±

# 4. feature selection

1. correlation â†’ 1ì°¨ feature selection

    ---

    merge event

    ---

2. embedded method â†’ 2ì°¨ feature selection

# 5. Modeling

# 6. Evaluate model

# 7. Develop Model